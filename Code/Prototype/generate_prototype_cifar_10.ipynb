{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:03<00:00, 54858389.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "# Correct way to set the default SSL context to use certifi's CA bundle\n",
    "def create_custom_https_context(*args, **kw):\n",
    "    context = ssl.create_default_context(*args, cafile=certifi.where(), **kw)\n",
    "    return context\n",
    "\n",
    "ssl._create_default_https_context = create_custom_https_context\n",
    "\n",
    "# Load CIFAR-10 dataset using torchvision\n",
    "def load_cifar10():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    # Convert datasets to NumPy arrays\n",
    "    train_images = np.array([trainset[i][0].numpy() for i in range(len(trainset))])\n",
    "    train_labels = np.array([trainset[i][1] for i in range(len(trainset))])\n",
    "    test_images = np.array([testset[i][0].numpy() for i in range(len(testset))])\n",
    "    test_labels = np.array([testset[i][1] for i in range(len(testset))])\n",
    "    \n",
    "    # Reshape images from CxHxW to HxWxC\n",
    "    train_images = np.transpose(train_images, (0, 2, 3, 1))\n",
    "    test_images = np.transpose(test_images, (0, 2, 3, 1))\n",
    "    \n",
    "    return (train_images * 255).astype(np.uint8), train_labels, (test_images * 255).astype(np.uint8), test_labels\n",
    "\n",
    "# Function to create a prototype dataset\n",
    "def create_prototype_dataset(images, labels, prototype_size):\n",
    "    num_classes = 10\n",
    "    per_class = prototype_size // num_classes\n",
    "    indices = []\n",
    "    for class_id in range(num_classes):\n",
    "        class_indices = np.where(labels == class_id)[0]\n",
    "        class_indices = np.random.choice(class_indices, per_class, replace=False)\n",
    "        indices.extend(class_indices)\n",
    "    np.random.shuffle(indices)\n",
    "    prototype_images = images[indices]\n",
    "    prototype_labels = labels[indices]\n",
    "    return prototype_images, prototype_labels\n",
    "\n",
    "# Function to create directories for dataset\n",
    "def create_directories(base_dir, class_names):\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(base_dir, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "\n",
    "# Function to save images\n",
    "def save_images(images, labels, base_dir, class_names):\n",
    "    for idx, (image, label) in enumerate(zip(images, labels)):\n",
    "        class_name = class_names[label]\n",
    "        file_name = f'{idx}.png'\n",
    "        file_path = os.path.join(base_dir, class_name, file_name)\n",
    "        img = Image.fromarray(image)\n",
    "        img.save(file_path)\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    train_images, train_labels, test_images, test_labels = load_cifar10()\n",
    "\n",
    "    # Create prototype datasets\n",
    "    prototype_train_size = 5000\n",
    "    prototype_test_size = 1000\n",
    "    proto_train_images, proto_train_labels = create_prototype_dataset(train_images, train_labels, prototype_train_size)\n",
    "    proto_test_images, proto_test_labels = create_prototype_dataset(test_images, test_labels, prototype_test_size)\n",
    "\n",
    "    # Split the prototype training set into training and validation sets\n",
    "    proto_train_images, proto_val_images, proto_train_labels, proto_val_labels = train_test_split(\n",
    "        proto_train_images, proto_train_labels, test_size=0.2, stratify=proto_train_labels)\n",
    "\n",
    "    # Define class names and base directories\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    train_dir = './prototype_generated/train'\n",
    "    val_dir = './prototype_generated/validation'\n",
    "    test_dir = './prototype_generated/test'\n",
    "\n",
    "    # Create directories and save prototype images\n",
    "    create_directories(train_dir, class_names)\n",
    "    create_directories(val_dir, class_names)\n",
    "    create_directories(test_dir, class_names)\n",
    "    save_images(proto_train_images, proto_train_labels, train_dir, class_names)\n",
    "    save_images(proto_val_images, proto_val_labels, val_dir, class_names)\n",
    "    save_images(proto_test_images, proto_test_labels, test_dir, class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
